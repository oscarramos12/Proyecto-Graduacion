Este trabajo de graduación se enfoca en la generación de una metodología que facilite la recolección y procesamiento de datos destinados a entrenar un LLM (Large Language Model) para
garantizar la calidad y eficacia del modelo resultante y para optimizar el proceso de entrenamiento.
Se dio un enfoque principalemente a la recolección inicial de archivos en formato PDF utilizando
un web scraper y propone un marco de trabajo para la limpieza de datos que abarca desde la detección
y eliminación de valores atípicos hasta la generación de reportes de las tendencias encontradas en
los archivos, lo que contribuye a la mejora de la coherencia y cohesión de los archivos.
Se lleva a cabo una evaluación de la calidad de los datos entrenando un modelo GPT-2 (Generative Pre-trained Transformer) de pequeña escala y comparando los textos generados por el modelo
con los datos limpios y el texto extraído directamente de los archivos.
Finalmente, este proyecto contribuye al avance en el campo de la inteligencia artificial y el
procesamiento del lenguaje natural al establecer pautas y buenas prácticas para la recolección y
limpieza de datos destinados a entrenar modelos de lenguaje.
